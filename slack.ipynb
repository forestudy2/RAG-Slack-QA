{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸŒ¿ STEP 1-1 - Multi-turn 1. ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import dotenv\n",
    "from operator import itemgetter\n",
    "from slack_bolt import App\n",
    "from slack_bolt.adapter.socket_mode import SocketModeHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote import logging\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "logging.langsmith(\"RAG-Slack-Bot\")\n",
    "app = App(token=os.environ.get(\"SLACK_BOT_TOKEN\"))\n",
    "llm = ChatOllama(model=\"EEVE-Korean-10.8B:latest\", max_tokens=100, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\" You are an assistant who can help with a variety of tasks.  \n",
    "Your name is KPT. Please be sure to answer in Korean. Can provide valuable insight and information on a wide range of topics. \n",
    "They can also help you with specific questions and chat about specific topics. \n",
    "Please refer to the \"Chat History\" and keep your answer short and concise with 2-3 sentences.\n",
    "If the answer is incorrect, please mention \"unsure answer\".\n",
    "\n",
    "#Chat History: {history}\n",
    "\n",
    "#Human: {human_input}\n",
    "\n",
    "#Assistant: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"history\", \"human_input\"], template=template)\n",
    "\n",
    "\n",
    "# Function to create a new LLMChain with a fresh memory\n",
    "def create_chatgpt_chain():\n",
    "    memory = ConversationBufferWindowMemory(k=3)\n",
    "    return LLMChain(llm=llm, prompt=prompt, verbose=True, memory=memory)\n",
    "\n",
    "\n",
    "# Create a new LLMChain instance with fresh memory\n",
    "chatgpt_chain = create_chatgpt_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event handler for Slack\n",
    "@app.event(\"app_mention\")\n",
    "def handle_app_mention_events(body, say, logger):\n",
    "    message = body[\"event\"][\"text\"]\n",
    "\n",
    "    output = chatgpt_chain.predict(human_input=message)\n",
    "    say(output)\n",
    "\n",
    "\n",
    "# Message handler for Slack\n",
    "@app.message(\".*\")\n",
    "def message_handler(message, say, logger):\n",
    "    print(message)\n",
    "\n",
    "    output = chatgpt_chain.predict(human_input=message[\"text\"])\n",
    "    say(output)\n",
    "\n",
    "\n",
    "# Start your app\n",
    "if __name__ == \"__main__\":\n",
    "    SocketModeHandler(app, os.environ[\"SLACK_APP_TOKEN\"]).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸŒ¿ STEP 2 - Multi-turn 2. RunnableWithMessageHistory\n",
    "\n",
    "`RunnableWithMessageHistory` ì˜ ì´ˆê¸°ê°’ì— `session_id` í‚¤ë¥¼ Default ë¡œ ì‚½ì…í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆìœ¼ë©°,  \n",
    "\n",
    "ì´ ì½”ë“œë¡œ ì¸í•˜ì—¬ `RunnableWithMessageHistory` ëŠ” ëŒ€í™” ìŠ¤ë ˆë“œ ê´€ë¦¬ë¥¼ `session_id` ë¡œ í•œë‹¤ëŠ” ê²ƒì„ ê°„ì ‘ì ìœ¼ë¡œ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.   \n",
    "\n",
    "ì¦‰, ëŒ€í™” ìŠ¤ë ˆë“œë³„ ê´€ë¦¬ëŠ” `session_id` ë³„ë¡œ êµ¬í˜„í•¨ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ê°™ì€ `session_id` ë¥¼ ì…ë ¥í•˜ë©´ ì´ì „ ëŒ€í™” ìŠ¤ë ˆë“œì˜ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ê¸° ë•Œë¬¸ì— ì´ì–´ì„œ ëŒ€í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤!\n",
    "\n",
    "   \n",
    "\n",
    "```python\n",
    "if history_factory_config:\n",
    "    _config_specs = history_factory_config\n",
    "else:\n",
    "    # If not provided, then we'll use the default session_id field\n",
    "    _config_specs = [\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"session_id\",\n",
    "            annotation=str,\n",
    "            name=\"Session ID\",\n",
    "            description=\"Unique identifier for a session.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ]\n",
    "```\n",
    "\n",
    "ë”°ë¼ì„œ, `invoke()` ì‹œ `config={\"configurable\": {\"session_id\": \"ì„¸ì…˜IDì…ë ¥\"}}` ì½”ë“œë¥¼ ë°˜ë“œì‹œ ì§€ì •í•´ ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "RAG-Slack-Bot\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import dotenv\n",
    "from operator import itemgetter\n",
    "from slack_bolt import App\n",
    "from slack_bolt.adapter.socket_mode import SocketModeHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote import logging\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "logging.langsmith(\"RAG-Slack-Bot\")\n",
    "app = App(token=os.environ.get(\"SLACK_BOT_TOKEN\"))\n",
    "llm = ChatOllama(model=\"EEVE-Korean-10.8B:latest\", max_tokens=100, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\" You are an assistant who can help with a variety of tasks.  \n",
    "Your name is KPT. Please be sure to answer in Korean. Can provide valuable insight and information on a wide range of topics. \n",
    "They can also help you with specific questions and chat about specific topics. \n",
    "Please refer to the \"Chat History\" and keep your answer short and concise with 2-3 sentences.\n",
    "If the answer is incorrect, please mention \"unsure answer\".\n",
    "\n",
    "#Chat History: {history}\n",
    "\n",
    "#Human: {human_input}\n",
    "\n",
    "#Assistant: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(input_variables=[\"history\", \"human_input\"], template=template)\n",
    "\n",
    "chatgpt_chain = LLMChain(\n",
    "    llm=llm, prompt=prompt, output_parser=StrOutputParser(), verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store = {}  # ì„¸ì…˜ ê¸°ë¡ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "\n",
    "\n",
    "# def get_session_history(session_id):\n",
    "#     if session_id not in store:\n",
    "#         store[session_id] = ChatMessageHistory()\n",
    "#     return store[session_id]\n",
    "\n",
    "\n",
    "# def format_history(history):\n",
    "#     messages = []\n",
    "#     for msg in history.messages:\n",
    "#         if isinstance(msg, HumanMessage):\n",
    "#             messages.append(f\"Human: {msg.content}\")\n",
    "#         elif isinstance(msg, AIMessage):\n",
    "#             messages.append(f\"AI: {msg.content}\")\n",
    "#     return \"\\n\".join(messages)\n",
    "\n",
    "\n",
    "# chain_with_history = RunnableWithMessageHistory(\n",
    "#     chatgpt_chain,\n",
    "#     get_session_history,  # ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "#     input_messages_key=\"human_input\",  # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ í…œí”Œë¦¿ ë³€ìˆ˜ì— ë“¤ì–´ê°ˆ key\n",
    "#     history_messages_key=\"history\",  # ê¸°ë¡ ë©”ì‹œì§€ì˜ í‚¤\n",
    "# )\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     session_id = \"default\"  # ê³ ì •ëœ ì„¸ì…˜ IDë¥¼ ì‚¬ìš©\n",
    "\n",
    "#     while True:\n",
    "#         human_input = input(\"ì…ë ¥: \")  # ì‚¬ìš©ì ì…ë ¥ì„ ì½˜ì†”ì—ì„œ ë°›ê¸°\n",
    "#         if human_input.lower() in [\"exit\", \"quit\"]:\n",
    "#             break  # ì¢…ë£Œ ì¡°ê±´\n",
    "\n",
    "#         history = get_session_history(session_id)\n",
    "#         formatted_history = format_history(history)\n",
    "\n",
    "#         response = chain_with_history.invoke(\n",
    "#             {\"human_input\": human_input, \"history\": formatted_history},\n",
    "#             {\"configurable\": {\"session_id\": session_id}},  # configì— session_id ì¶”ê°€\n",
    "#         )\n",
    "\n",
    "#         response_text = response.get(\"text\", \"ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "#         print(f\"AI: {response_text}\")\n",
    "\n",
    "#         # ì„¸ì…˜ ê¸°ë¡ ì—…ë°ì´íŠ¸\n",
    "#         history.add_message(HumanMessage(human_input))\n",
    "#         history.add_message(AIMessage(response_text))\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slack ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}  # ì„¸ì…˜ ê¸°ë¡ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "\n",
    "\n",
    "def get_session_history(\n",
    "    session_id,\n",
    "):  # ì£¼ì–´ì§„ ì„¸ì…˜ IDì— ëŒ€í•œ ëŒ€í™” ê¸°ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤. ì„¸ì…˜ IDê°€ ì²˜ìŒ ìš”ì²­ëœ ê²½ìš°ì—ëŠ” ìƒˆë¡œìš´ ëŒ€í™” ê¸°ë¡ ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "    print(f\"[Conversation Session ID]: {session_id}\")\n",
    "    if session_id not in store:  # ì„¸ì…˜ IDê°€ storeì— ì—†ëŠ” ê²½ìš°\n",
    "        store[session_id] = (\n",
    "            ChatMessageHistory()\n",
    "        )  # ìƒˆë¡œìš´ ChatMessageHistory ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ storeì— ì €ì¥\n",
    "    return store[session_id]  # í•´ë‹¹ ì„¸ì…˜ IDì— ëŒ€í•œ ì„¸ì…˜ ê¸°ë¡ ë°˜í™˜\n",
    "\n",
    "\n",
    "def format_history(history):  # ëŒ€í™” ê¸°ë¡ ê°ì²´ë¥¼ í¬ë§·í•˜ì—¬ ë¬¸ìì—´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "    messages = []\n",
    "    for msg in history.messages:\n",
    "        if isinstance(msg, HumanMessage):  # ë©”ì‹œì§€ê°€ HumanMessage íƒ€ì…ì¸ ê²½ìš°\n",
    "            messages.append(\n",
    "                f\"Human: {msg.content}\"\n",
    "            )  # 'Human: ' ì ‘ë‘ì–´ì™€ í•¨ê»˜ ë©”ì‹œì§€ ë‚´ìš© ì¶”ê°€\n",
    "        elif isinstance(msg, AIMessage):  # ë©”ì‹œì§€ê°€ AIMessage íƒ€ì…ì¸ ê²½ìš°\n",
    "            messages.append(\n",
    "                f\"AI: {msg.content}\"\n",
    "            )  # 'AI: ' ì ‘ë‘ì–´ì™€ í•¨ê»˜ ë©”ì‹œì§€ ë‚´ìš© ì¶”ê°€\n",
    "    return \"\\n\".join(messages)  # ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¤„ ë°”ê¿ˆìœ¼ë¡œ ê²°í•©í•˜ì—¬ ë¬¸ìì—´ ë°˜í™˜\n",
    "\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chatgpt_chain,\n",
    "    get_session_history,  # ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "    input_messages_key=\"human_input\",  # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ í…œí”Œë¦¿ ë³€ìˆ˜ì— ë“¤ì–´ê°ˆ key\n",
    "    history_messages_key=\"history\",  # ê¸°ë¡ ë©”ì‹œì§€ì˜ í‚¤\n",
    ")\n",
    "\n",
    "\n",
    "# Slack ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬\n",
    "@app.event(\"app_mention\")\n",
    "def handle_app_mention_events(body, say, logger):\n",
    "    session_id = body[\"event\"][\"channel\"]  # ì´ë²¤íŠ¸ê°€ ë°œìƒí•œ ì±„ë„ IDë¥¼ ì„¸ì…˜ IDë¡œ ì‚¬ìš©\n",
    "    message = body[\"event\"][\"text\"]  # ë©”ì‹œì§€ ë‚´ìš©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    history = get_session_history(session_id)  # í•´ë‹¹ ì„¸ì…˜ IDì˜ ëŒ€í™” ê¸°ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    formatted_history = format_history(history)  # ëŒ€í™” ê¸°ë¡ì„ í¬ë§·í•˜ì—¬ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "\n",
    "    # chain_with_historyë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±\n",
    "    response = chain_with_history.invoke(\n",
    "        {\"human_input\": message, \"history\": formatted_history},\n",
    "        config={\"configurable\": {\"session_id\": session_id}},\n",
    "    )\n",
    "\n",
    "    # ì‘ë‹µ ë”•ì…”ë„ˆë¦¬ì—ì„œ 'text' í•„ë“œë§Œ ì¶”ì¶œí•˜ì—¬ ìŠ¬ë™ì— ì „ì†¡í•©ë‹ˆë‹¤.\n",
    "    response_text = response.get(\"text\", \"ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "    say(response_text)\n",
    "\n",
    "\n",
    "# Slack ë©”ì‹œì§€ í•¸ë“¤ëŸ¬\n",
    "@app.message(\".*\")\n",
    "def message_handler(message, say, logger):\n",
    "    session_id = message[\"channel\"]\n",
    "    text = message[\"text\"]\n",
    "    history = get_session_history(session_id)\n",
    "    formatted_history = format_history(history)\n",
    "\n",
    "    # chain_with_historyë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±\n",
    "    response = chain_with_history.invoke(\n",
    "        {\"human_input\": text, \"history\": formatted_history},\n",
    "        config={\"configurable\": {\"session_id\": session_id}},\n",
    "    )\n",
    "\n",
    "    # ì‘ë‹µì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ìŠ¬ë™ì— ì „ì†¡\n",
    "    response_text = response.get(\"text\", \"ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "    say(response_text)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    SocketModeHandler(app, os.environ[\"SLACK_APP_TOKEN\"]).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸŒ¿ STEP 3 - Retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ğŸ‘‰ğŸ» NotionDirectoryLoader\n",
    "https://logan-vendrix.medium.com/create-your-own-notion-chatbot-with-langchain-openai-and-streamlit-fcb385f432a2\n",
    "\n",
    "#### ğŸ‘‰ğŸ» RecursiveCharacterTextSplitter\n",
    "https://api.python.langchain.com/en/latest/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.parse\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Documents length: 219\n",
      "*** Decoded content for document 1: # ëŒ€í•™êµ ì´ìˆ˜ ê³¼ëª© ë³„ ì œì¶œ ë³´ê³ ì„œ ë° ë°œí‘œ ìë£Œ\n",
      "\n",
      "[[ê³¼ëª©ë³„ ë³´ê³ ì„œ & ë°œí‘œ ìë£Œ]-ì–´ì…ˆë¸”ë¦¬ì–¸ì–´](á„ƒá…¢á„’á…¡á†¨á„€á…­ á„‹á…µá„‰á…® á„€á…ªá„†á…©á†¨ á„‡á…§á†¯ á„Œá…¦á„á…®á†¯ á„‡á…©á„€á…©á„‰á…¥ á„†á…µá†¾ á„‡á…¡á†¯á„‘á…­ á„Œá…¡á„…á…­ 9baa031ab64a474e8222d328d8b554f3/[á„€á…ªá„†á…©á†¨á„‡á…§á†¯ á„‡á…©á„€á…©á„‰á…¥ & á„‡á…¡á†¯á„‘á…­ á„Œá…¡á„…á…­]-á„‹á…¥á„‰á…¦á†·á„‡á…³á†¯á„…á…µá„‹á…¥á†«á„‹á…¥ c05274e93077416ba857cf01009bbd83.csv)\n"
     ]
    }
   ],
   "source": [
    "def decode_url(encoded_url):\n",
    "    return urllib.parse.unquote(encoded_url)\n",
    "\n",
    "\n",
    "# ë¬¸ì„œì˜ URL ì¸ì½”ë”©ëœ ê²½ë¡œë¥¼ ë””ì½”ë”©í•˜ëŠ” í•¨ìˆ˜\n",
    "def decode_documents(docs):\n",
    "    decoded_docs = []\n",
    "    for doc in docs:\n",
    "        decoded_content = decode_url(doc.page_content)\n",
    "        decoded_doc = doc  # ê¸°ì¡´ ë¬¸ì„œ ê°ì²´ë¥¼ ì‚¬ìš©\n",
    "        decoded_doc.page_content = decoded_content  # URL ë””ì½”ë”©ëœ ë‚´ìš©ìœ¼ë¡œ ì—…ë°ì´íŠ¸\n",
    "        decoded_docs.append(decoded_doc)\n",
    "    return decoded_docs\n",
    "\n",
    "\n",
    "# íŒŒì¼ ë¡œë”© ë° ë””ì½”ë”© ì‘ì—…\n",
    "def load_and_decode_documents(folder_path):\n",
    "    # STEP 1. ë¬¸ì„œ ë¡œë“œ(Load Documents)\n",
    "    loader = NotionDirectoryLoader(folder_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # STEP 2: ë¬¸ì„œ ë¶„í• (Split Documents)\n",
    "    markdown_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"#\", \"##\", \"###\", \"\\n\\n\", \"\\n\", \".\"],\n",
    "        chunk_size=1500,\n",
    "        chunk_overlap=100,\n",
    "    )\n",
    "    docs = markdown_splitter.split_documents(documents)\n",
    "\n",
    "    # URL ì¸ì½”ë”© ë””ì½”ë”©\n",
    "    decoded_docs = decode_documents(docs)\n",
    "\n",
    "    return decoded_docs\n",
    "\n",
    "\n",
    "# Notion content í´ë” ê²½ë¡œ\n",
    "folder_path = \"notion_content\"\n",
    "decoded_documents = load_and_decode_documents(folder_path)\n",
    "\n",
    "# ë””ì½”ë”©ëœ ë¬¸ì„œ ë‚´ìš© ì¶œë ¥\n",
    "print(f\"*** Documents length: {len(decoded_documents)}\")\n",
    "print(f\"*** Decoded content for document 1: {decoded_documents[0].page_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoded_documents[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: ì„ë² ë”©(Embedding) ìƒì„±\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# STEP 4: DB ìƒì„±(Create DB) ë° ì €ì¥\n",
    "vectorstore = FAISS.from_documents(documents=decoded_documents, embedding=embeddings)\n",
    "# STEP 5 : ê²€ìƒ‰ê¸°(Retriever) ìƒì„±\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'notion_content/ğŸ« ëŒ€í•™êµ 79bb72c98b654231a8d07dc2f8f324f1/ëŒ€í•™êµ ì´ìˆ˜ ê³¼ëª© ë° ì„±ì  094fc5a517e44a0ea05c6b81d867901d/[ê³¼ëª© ì„±ì ] (1) dbd0203c06854a9e85e99c00194fb1e5/ì •ë³´ë³´í˜¸ê°œë¡ -[ì „ê³µ] 195677ad9ea444108cda5dc447384488.md'}, page_content='# ì •ë³´ë³´í˜¸ê°œë¡ -[ì „ê³µ]\\n\\nTags: 1í•™ë…„, 2í•™ê¸°\\nGrade: A+'),\n",
       " Document(metadata={'source': 'notion_content/ğŸ« ëŒ€í•™êµ 79bb72c98b654231a8d07dc2f8f324f1/ëŒ€í•™êµ ì´ìˆ˜ ê³¼ëª© ë° ì„±ì  094fc5a517e44a0ea05c6b81d867901d/[ê³¼ëª© ì„±ì ] (1) dbd0203c06854a9e85e99c00194fb1e5/ì •ë³´ì´ë¡ -[ì „ê³µ] 00fcccf2f4d541758925690b919730ba.md'}, page_content='# ì •ë³´ì´ë¡ -[ì „ê³µ]\\n\\nTags: 2í•™ê¸°, 3í•™ë…„\\nGrade: A0\\n\\n##'),\n",
       " Document(metadata={'source': 'notion_content/ğŸ« ëŒ€í•™êµ 79bb72c98b654231a8d07dc2f8f324f1/ëŒ€í•™êµ ì´ìˆ˜ ê³¼ëª© ë° ì„±ì  094fc5a517e44a0ea05c6b81d867901d.md'}, page_content='# ëŒ€í•™êµ ì´ìˆ˜ ê³¼ëª© ë° ì„±ì \\n\\n[[ê³¼ëª© ì„±ì ] (1)](á„ƒá…¢á„’á…¡á†¨á„€á…­ á„‹á…µá„‰á…® á„€á…ªá„†á…©á†¨ á„†á…µá†¾ á„‰á…¥á†¼á„Œá…¥á†¨ 094fc5a517e44a0ea05c6b81d867901d/[á„€á…ªá„†á…©á†¨ á„‰á…¥á†¼á„Œá…¥á†¨] (1) dbd0203c06854a9e85e99c00194fb1e5.csv)'),\n",
       " Document(metadata={'source': 'notion_content/ğŸ« ëŒ€í•™êµ 79bb72c98b654231a8d07dc2f8f324f1/ëŒ€í•™êµ ì´ìˆ˜ ê³¼ëª© ë° ì„±ì  094fc5a517e44a0ea05c6b81d867901d/[ê³¼ëª© ì„±ì ] (1) dbd0203c06854a9e85e99c00194fb1e5/ìš´ì˜ì²´ì œë³´ì•ˆ-[ì „ê³µ] e871cc5d9ba341e2926a8c27e8020755.md'}, page_content='# ìš´ì˜ì²´ì œë³´ì•ˆ-[ì „ê³µ]\\n\\nTags: 1í•™ê¸°, 3í•™ë…„\\nGrade: A+')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"ì •ë³´ë³´í˜¸ê°œë¡  ì„±ì ì€?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever í…ŒìŠ¤íŠ¸ ì½”ë“œ\n",
    "* ê°„ë‹¨í•œ chain êµ¬í˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  ê³¼ëª© ë³´ê³ ì„œì™€ ê´€ë ¨ëœ íŒŒì¼ë“¤ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. ë‹¤ìŒì€ ê´€ë ¨ ë¬¸ì„œë“¤ì…ë‹ˆë‹¤:\n",
      "\n",
      "* ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ìµœì¢…ë³´ê³ ì„œ.pdf (á„á…±á„‹á…£á†¨á„Œá…¥á†·á„‡á…®á†«á„‰á…¥á†¨á„€á…µá„‰á…®á†¯_4á„Œá…©/ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ìµœì¢…ë³´ê³ ì„œ.pdf)\n",
      "* ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ì¤‘ê°„ë³´ê³ ì„œ.pdf (á„á…±á„‹á…£á†¨á„Œá…¥á†·á„‡á…®á†«á„‰á…¥á†¨á„€á…µá„‰á…®á†¯_4á„Œá…©/ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ì¤‘ê°„ë³´ê³ ì„œ.pdf)\n",
      "* 20194577_ê¹€ìˆ˜í˜„_ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  ê°œì¸ë³´ê³ ì„œ.pdf (20194577_á„€á…µá†·á„‰á…®á„’á…§á†«_á„á…±á„‹á…£á†¨á„Œá…¥á†·á„‡á…®á†«á„‰á…¥á†¨á„€á…µá„‰á…®á†¯ á„€á…¢á„‹á…µá†«á„‡á…©á„€á…©á„‰á…¥/20194577_ê¹€ìˆ˜í˜„_ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _ê°œì¸ë³´ê³ ì„œ.pdf)\n",
      "\n",
      "í•´ë‹¹ íŒŒì¼ë“¤ì€ ëŒ€í•™êµ ì´ìˆ˜ ê³¼ëª© ë³„ ì œì¶œ ë³´ê³ ì„œ ë° ë°œí‘œ ìë£Œ í´ë”ì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤ (ëŒ€í•™êµ ì´ìˆ˜ ê³¼ëª© ë³„ ì œì¶œ ë³´ê³ ì„œ ë° ë°œí‘œ ìë£Œ 9baa031ab64a474e8222d328d8b554f3).\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant who can help with a variety of tasks.  \n",
    "Your name is KPT. Please be sure to answer in Korean. Can provide valuable insight and information on a wide range of topics. \n",
    "They can also help you with specific questions and chat about specific topics. \n",
    "Please refer to the \"Chat History\" and keep your answer short and concise with 2-3 sentences.\n",
    "If the answer is incorrect, please mention \"unsure answer\".\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "\n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "# llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "llm = ChatOllama(model=\"EEVE-Korean-10.8B:latest\", max_tokens=100, temperature=0)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# question = \"ëŒ€í•™êµ êµë‚´ í™œë™ì„ ë¬´ì—‡ì„ í–ˆì„ê¹Œ? ê´€ë ¨ ë¬¸ì„œë¡œ ëœ csvë‚˜ pdf ì°¾ì•„ì¤˜.\"\n",
    "question = \"ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  ê³¼ëª© ë³´ê³ ì„œë¥¼ ì‘ì„±í•œ ì ì´ ìˆì—ˆë‚˜? ìˆë‹¤ë©´ ê´€ë ¨ ë¬¸ì„œë¡œ ëœ csv í˜•íƒœì˜ íŒŒì¼ì´ë‚˜ pdf í˜•íƒœì˜ íŒŒì¼ì„ ì°¾ì•„ì£¼ê³  íŒŒì¼ì´ ìˆëŠ” ê²½ë¡œë„ ì•Œë ¤ì¤˜.\"\n",
    "response = chain.invoke(question)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever í…ŒìŠ¤íŠ¸ ì½”ë“œ\n",
    "* LLMChainìœ¼ë¡œ êµ¬í˜„\n",
    "* ì½”ë“œ ì‹¤í–‰ ì‹œ ë‹¤ìŒê³¼ ê°™ì€ í”„ë¡¬í”„íŠ¸ëŠ” í™˜ê° í˜„ìƒì´ ë³´ì—¬ ìˆ˜ì • ì§„í–‰í•˜ì˜€ìŒ\n",
    "\n",
    "==============================================================================================================================\n",
    "\n",
    "[before]  \n",
    "\n",
    "```python   \n",
    "\"\"\"You are an assistant who can help with a variety of tasks.  \n",
    "Your name is KPT. Please be sure to answer in Korean. Can provide valuable insight and information on a wide range of topics. \n",
    "They can also help you with specific questions and chat about specific topics. \n",
    "Please refer to the \"Chat History\" and keep your answer short and concise with 2-3 sentences.\n",
    "If the answer is incorrect, please mention \"unsure answer\".\"\"\"\n",
    "```\n",
    "\n",
    "ì·¨ì•½ì  ë¶„ì„ ê¸°ìˆ  ê³¼ëª© ë³´ê³ ì„œ ì‘ì„±ì— ëŒ€í•œ ë¬¸ì˜ì— ë„ì›€ì„ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì œê³µí•´ì£¼ì‹  ë§¥ë½ê³¼ íƒœê·¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ìŒê³¼ ê°™ì€ ê´€ë ¨ ë¬¸ì„œë“¤ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n",
    "\n",
    "1. ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ìµœì¢…ë³´ê³ ì„œ.pdf (PDF íŒŒì¼)\n",
    "2. ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ì¤‘ê°„ë³´ê³ ì„œ.pdf (PDF íŒŒì¼)\n",
    "3. 20194577_ê¹€ìˆ˜í˜„_ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  ê°œì¸ë³´ê³ ì„œ.pdf (PDF íŒŒì¼)\n",
    "\n",
    "ì´ ë¬¸ì„œë“¤ì€ ëª¨ë‘ ì·¨ì•½ì  ë¶„ì„ ê¸°ìˆ  ê³¼ëª©ê³¼ ê´€ë ¨ì´ ìˆìœ¼ë©°, ë³´ê³ ì„œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. í•´ë‹¹ íŒŒì¼ë“¤ì€ ì œê³µëœ URLì—ì„œ ì°¾ì•„ë³´ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "- ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ìµœì¢…ë³´ê³ ì„œ.pdf: <https://drive.google.com/file/d/020d2d377f7142f389ff265e7df...>\n",
    "- ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ì¤‘ê°„ë³´ê³ ì„œ.pdf: <https://drive.google.com/file/d/bf99519803114166ac6ba...>\n",
    "- 20194577_ê¹€ìˆ˜í˜„_ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  ê°œì¸ë³´ê³ ì„œ.pdf: <https://drive.google.com/file/d/fa8871ee...>\n",
    "\n",
    "ì´ íŒŒì¼ë“¤ì´ ë„ì›€ì´ ë˜ê¸¸ ë°”ëë‹ˆë‹¤! ì¶”ê°€ì ì¸ ì§ˆë¬¸ì´ ìˆê±°ë‚˜ ë” ìì„¸í•œ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¸ì˜í•´ ì£¼ì„¸ìš”.\n",
    "\n",
    "==============================================================================================================================\n",
    "\n",
    "[after]\n",
    "\n",
    "```python    \n",
    "\"\"\"Your name is KPT. Please be sure to answer in Korean. Can provide valuable insight and information on a wide range of topics. \n",
    "They can also help you with specific questions and chat about specific topics. \n",
    "Please refer to the \"Chat History\" and keep your answer short and concise with 2-3 sentences.\n",
    "If the answer is incorrect, please mention \"unsure answer\".\n",
    "*** Be sure to answer only using the information given, and be sure to include a separator such as '/' in the file path and specify folder information as well. ***\"\"\" \n",
    "```\n",
    "\n",
    "ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  ê³¼ëª© ë³´ê³ ì„œ ì‘ì„±ì„ ìœ„í•œ ê´€ë ¨ ë¬¸ì„œë¡œ ëœ CSV í˜•íƒœì˜ íŒŒì¼ì´ë‚˜ PDF í˜•íƒœì˜ íŒŒì¼ì„ ì°¾ê³ ì í•œë‹¤ë©´, ì œê³µëœ ë§¥ë½ì— ìˆëŠ” íŒŒì¼ë“¤ì„ ì°¸ê³ í•˜ì„¸ìš”. ë‹¤ìŒì€ í•´ë‹¹ íŒŒì¼ë“¤ì˜ ê²½ë¡œì™€ ì´ë¦„ì…ë‹ˆë‹¤:\n",
    "\n",
    "1. ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ìµœì¢…ë³´ê³ ì„œ.pdf (ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  4ì¡° ìµœì¢… ë³´ê³ ì„œ)\n",
    "2. ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ì¤‘ê°„ë³´ê³ ì„œ.pdf (ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  4ì¡° ì¤‘ê°„ ë³´ê³ ì„œ)\n",
    "3. 20194577_ê¹€ìˆ˜í˜„_ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  ê°œì¸ë³´ê³ ì„œ.pdf (20194577 ê¹€ìˆ˜í˜„ ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  ê°œì¸ ë³´ê³ ì„œ)\n",
    "\n",
    "ì´ íŒŒì¼ë“¤ì€ ì œê³µëœ ë§¥ë½ì— ìˆëŠ” í´ë” ì•ˆì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "- ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ìµœì¢…ë³´ê³ ì„œ.pdf: á„á…±á„‹á…£á†¨á„Œá…¥á†·á„‡á…®á†«á„‰á…¥á†¨á„€á…µá„‰á…®á†¯_4á„Œá…©/ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ìµœì¢…ë³´ê³ ì„œ.pdf\n",
    "- ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ì¤‘ê°„ë³´ê³ ì„œ.pdf: á„á…±á„‹á…£á†¨á„Œá…¥á†·á„‡á…®á†«á„‰á…¥á†¨á„€á…µá„‰á…®á†¯_4á„Œá…©/ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ì¤‘ê°„ë³´ê³ ì„œ.pdf\n",
    "- 20194577_ê¹€ìˆ˜í˜„_ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  ê°œì¸ë³´ê³ ì„œ.pdf: 20194577_á„€á…µá†·á„‰á…®á„’á…§á†«/20194577_ê¹€ìˆ˜í˜„_ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _ê°œì¸ë³´ê³ ì„œ.pdf\n",
    "\n",
    "ì´ íŒŒì¼ë“¤ì„ ì°¾ìœ¼ë ¤ë©´ ì œê³µëœ ê²½ë¡œì™€ ì´ë¦„ì„ ì°¸ê³ í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour name is KPT. Please be sure to answer in Korean. Can provide valuable insight and information on a wide range of topics. \n",
      "They can also help you with specific questions and chat about specific topics. \n",
      "Please refer to the \"Chat History\" and keep your answer short and concise with 2-3 sentences.\n",
      "If the answer is incorrect, please mention \"unsure answer\".\n",
      "*** Be sure to answer only using the information given, and be sure to include a separator such as '/' in the file path and specify folder information as well. ***.\n",
      "\n",
      "#Question: \n",
      "ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  ê³¼ëª© ë³´ê³ ì„œë¥¼ ì‘ì„±í•œ ì ì´ ìˆì—ˆë‚˜? ìˆë‹¤ë©´ ê´€ë ¨ ë¬¸ì„œë¡œ ëœ csv í˜•íƒœì˜ íŒŒì¼ì´ë‚˜ pdf í˜•íƒœì˜ íŒŒì¼ì„ ì°¾ì•„ì£¼ê³  íŒŒì¼ì´ ìˆëŠ” ê²½ë¡œë„ ì•Œë ¤ì¤˜. \n",
      "\n",
      "#Context: \n",
      "[[ê³¼ëª©ë³„ ë³´ê³ ì„œ & ë°œí‘œ ìë£Œ]-ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  (Team Project)](á„ƒá…¢á„’á…¡á†¨á„€á…­ á„‹á…µá„‰á…® á„€á…ªá„†á…©á†¨ á„‡á…§á†¯ á„Œá…¦á„á…®á†¯ á„‡á…©á„€á…©á„‰á…¥ á„†á…µá†¾ á„‡á…¡á†¯á„‘á…­ á„Œá…¡á„…á…­ 9baa031ab64a474e8222d328d8b554f3/[á„€á…ªá„†á…©á†¨á„‡á…§á†¯ á„‡á…©á„€á…©á„‰á…¥ & á„‡á…¡á†¯á„‘á…­ á„Œá…¡á„…á…­]-á„á…±á„‹á…£á†¨á„Œá…¥á†·á„‡á…®á†«á„‰á…¥á†¨á„€á…µá„‰á…®á†¯ b837089ae9044ffcbb7911edef07eaa7.csv)\n",
      "# ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ìµœì¢…ë³´ê³ ì„œ\n",
      "\n",
      "Tags: Report\n",
      "\n",
      "[ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ìµœì¢…ë³´ê³ ì„œ.pdf](á„á…±á„‹á…£á†¨á„Œá…¥á†·á„‡á…®á†«á„‰á…¥á†¨á„€á…µá„‰á…®á†¯_4á„Œá…©_á„á…¬á„Œá…©á†¼á„‡á…©á„€á…©á„‰á…¥ 020d2d377f7142f389ff265e7dff340c/ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ìµœì¢…ë³´ê³ ì„œ.pdf)\n",
      "# ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ì¤‘ê°„ë³´ê³ ì„œ\n",
      "\n",
      "Tags: Report\n",
      "\n",
      "[ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ì¤‘ê°„ë³´ê³ ì„œ.pdf](á„á…±á„‹á…£á†¨á„Œá…¥á†·á„‡á…®á†«á„‰á…¥á†¨á„€á…µá„‰á…®á†¯_4á„Œá…©_á„Œá…®á†¼á„€á…¡á†«á„‡á…©á„€á…©á„‰á…¥ bf99519803114166ac6bab758ad4b730/ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ì¤‘ê°„ë³´ê³ ì„œ.pdf)\n",
      "# 20194577_ê¹€ìˆ˜í˜„_ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  ê°œì¸ë³´ê³ ì„œ\n",
      "\n",
      "Tags: Report\n",
      "\n",
      "[20194577_ê¹€ìˆ˜í˜„_ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  ê°œì¸ë³´ê³ ì„œ.pdf](20194577_á„€á…µá†·á„‰á…®á„’á…§á†«_á„á…±á„‹á…£á†¨á„Œá…¥á†·á„‡á…®á†«á„‰á…¥á†¨á„€á…µá„‰á…®á†¯ á„€á…¢á„‹á…µá†«á„‡á…©á„€á…©á„‰á…¥ fa8871eef3fd4c5ab136743ee04e03a9/20194577_ê¹€ìˆ˜í˜„_ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _ê°œì¸ë³´ê³ ì„œ.pdf) \n",
      "\n",
      "#Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  ê³¼ëª© ë³´ê³ ì„œ ì‘ì„±ì„ ìœ„í•œ ê´€ë ¨ ë¬¸ì„œë¡œ ëœ CSV í˜•íƒœì˜ íŒŒì¼ì´ë‚˜ PDF í˜•íƒœì˜ íŒŒì¼ì„ ì°¾ê³ ì í•œë‹¤ë©´, ì œê³µëœ ë§¥ë½ì— ìˆëŠ” íŒŒì¼ë“¤ì„ ì°¸ê³ í•˜ì„¸ìš”. ë‹¤ìŒì€ í•´ë‹¹ íŒŒì¼ë“¤ì˜ ê²½ë¡œì™€ ì´ë¦„ì…ë‹ˆë‹¤:\n",
      "\n",
      "1. ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ìµœì¢…ë³´ê³ ì„œ.pdf (ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  4ì¡° ìµœì¢… ë³´ê³ ì„œ)\n",
      "2. ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ì¤‘ê°„ë³´ê³ ì„œ.pdf (ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  4ì¡° ì¤‘ê°„ ë³´ê³ ì„œ)\n",
      "3. 20194577_ê¹€ìˆ˜í˜„_ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  ê°œì¸ë³´ê³ ì„œ.pdf (20194577 ê¹€ìˆ˜í˜„ ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  ê°œì¸ ë³´ê³ ì„œ)\n",
      "\n",
      "ì´ íŒŒì¼ë“¤ì€ ì œê³µëœ ë§¥ë½ì— ìˆëŠ” í´ë” ì•ˆì— ìœ„ì¹˜í•´ ìˆìŠµë‹ˆë‹¤:\n",
      "\n",
      "- ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ìµœì¢…ë³´ê³ ì„œ.pdf: á„á…±á„‹á…£á†¨á„Œá…¥á†·á„‡á…®á†«á„‰á…¥á†¨á„€á…µá„‰á…®á†¯_4á„Œá…©/ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ìµœì¢…ë³´ê³ ì„œ.pdf\n",
      "- ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ì¤‘ê°„ë³´ê³ ì„œ.pdf: á„á…±á„‹á…£á†¨á„Œá…¥á†·á„‡á…®á†«á„‰á…¥á†¨á„€á…µá„‰á…®á†¯_4á„Œá…©/ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _4ì¡°_ì¤‘ê°„ë³´ê³ ì„œ.pdf\n",
      "- 20194577_ê¹€ìˆ˜í˜„_ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  ê°œì¸ë³´ê³ ì„œ.pdf: 20194577_á„€á…µá†·á„‰á…®á„’á…§á†«/20194577_ê¹€ìˆ˜í˜„_ì·¨ì•½ì ë¶„ì„ê¸°ìˆ _ê°œì¸ë³´ê³ ì„œ.pdf\n",
      "\n",
      "ì´ íŒŒì¼ë“¤ì„ ì°¾ìœ¼ë ¤ë©´ ì œê³µëœ ê²½ë¡œì™€ ì´ë¦„ì„ ì°¸ê³ í•˜ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# retriever ì„¤ì •\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Your name is KPT. Please be sure to answer in Korean. Can provide valuable insight and information on a wide range of topics. \n",
    "They can also help you with specific questions and chat about specific topics. \n",
    "Please refer to the \"Chat History\" and keep your answer short and concise with 2-3 sentences.\n",
    "If the answer is incorrect, please mention \"unsure answer\".\n",
    "*** Be sure to answer only using the information given, and be sure to include a separator such as '/' in the file path and specify folder information as well. ***.\n",
    "\n",
    "#Question: \n",
    "{question} \n",
    "\n",
    "#Context: \n",
    "{context} \n",
    "\n",
    "#Answer:\"\"\"\n",
    ")\n",
    "\n",
    "# LLM ì„¤ì •\n",
    "llm = ChatOllama(model=\"EEVE-Korean-10.8B:latest\", max_tokens=100, temperature=0)\n",
    "\n",
    "# LLMChain ì„¤ì •\n",
    "chain = LLMChain(prompt=prompt, llm=llm, output_parser=StrOutputParser(), verbose=True)\n",
    "\n",
    "\n",
    "def retrieve_documents(human_input, num_results=5):\n",
    "    # retrieverë¥¼ ì´ìš©í•˜ì—¬ ë¬¸ì„œ ê²€ìƒ‰\n",
    "    results = retriever.get_relevant_documents(human_input, k=num_results)\n",
    "    # ê²€ìƒ‰ëœ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë³‘í•©\n",
    "    return \"\\n\".join([doc.page_content for doc in results])\n",
    "\n",
    "\n",
    "# ì§ˆë¬¸ê³¼ ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì²´ì¸ì— ë„£ì–´ ì‹¤í–‰\n",
    "def main():\n",
    "    question = \"ì·¨ì•½ì ë¶„ì„ê¸°ìˆ  ê³¼ëª© ë³´ê³ ì„œë¥¼ ì‘ì„±í•œ ì ì´ ìˆì—ˆë‚˜? ìˆë‹¤ë©´ ê´€ë ¨ ë¬¸ì„œë¡œ ëœ csv í˜•íƒœì˜ íŒŒì¼ì´ë‚˜ pdf í˜•íƒœì˜ íŒŒì¼ì„ ì°¾ì•„ì£¼ê³  íŒŒì¼ì´ ìˆëŠ” ê²½ë¡œë„ ì•Œë ¤ì¤˜.\"\n",
    "\n",
    "    context = retrieve_documents(question, num_results=5)\n",
    "    inputs = {\"question\": question, \"context\": context}\n",
    "\n",
    "    response = chain.invoke(inputs)\n",
    "    response_text = response.get(\"text\", \"ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(response_text)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever & Model ì—°ë™ - Kernel ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model=\"EEVE-Korean-10.8B:latest\", max_tokens=100, temperature=0)\n",
    "\n",
    "template = \"\"\"Your name is KPT. Please be sure to answer in Korean. \n",
    "Can provide valuable insight and information on a wide range of topics. \n",
    "They can also help you with specific questions and chat about specific topics. \n",
    "Please refer to the \"Chat History\" and keep your answer short and concise with 2-3 sentences.\n",
    "If the answer is incorrect, please mention \"unsure answer\".\n",
    "*** Please mention and answer only the content related to Human's question! If the purpose is to greet you, just say hello, and if you are asking for information, ask them to provide the information. ***\n",
    "*** Be sure to answer only using the information given, and be sure to include a separator such as '/' in the file path and specify folder information as well. ***\n",
    "\n",
    "#Chat History: {history}\n",
    "\n",
    "#Context: {context}\n",
    "\n",
    "#Human: {human_input}\n",
    "\n",
    "#Assistant: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"human_input\", \"context\"], template=template\n",
    ")\n",
    "\n",
    "chatgpt_chain = LLMChain(\n",
    "    llm=llm, prompt=prompt, output_parser=StrOutputParser(), verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour name is KPT. Please be sure to answer in Korean. \n",
      "Can provide valuable insight and information on a wide range of topics. \n",
      "They can also help you with specific questions and chat about specific topics. \n",
      "Please refer to the \"Chat History\" and keep your answer short and concise with 2-3 sentences.\n",
      "If the answer is incorrect, please mention \"unsure answer\".\n",
      "*** Please mention and answer only the content related to Human's question! If the purpose is to greet you, just say hello, and if you are asking for information, ask them to provide the information. ***\n",
      "*** Be sure to answer only using the information given, and be sure to include a separator such as '/' in the file path and specify folder information as well. ***\n",
      "\n",
      "#Chat History: []\n",
      "\n",
      "#Context: # ì œëª© ì—†ìŒ\n",
      "# ì–´ì…ˆë¸”ë¦¬ì–¸ì–´-[ì „ê³µ]\n",
      "\n",
      "Tags: 1í•™ê¸°, 2í•™ë…„\n",
      "Grade: A+\n",
      "# ì „ê³µì˜ì–´-[ì „ê³µ]\n",
      "\n",
      "Tags: 1í•™ê¸°, 3í•™ë…„\n",
      "Grade: A0\n",
      "# í™˜ê²½ê³¼ì—ë„ˆì§€-[êµì–‘]\n",
      "\n",
      "Tags: 1í•™ê¸°, 3í•™ë…„\n",
      "Grade: A0\n",
      "\n",
      "#Human: ì•ˆë…•?\n",
      "\n",
      "#Assistant: \n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: ì•ˆë…•í•˜ì„¸ìš”! ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ì‹  ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”. ì£¼ì–´ì§„ ì •ë³´ ì•ˆì—ì„œ ìµœì„ ì„ ë‹¤í•´ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì €ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë§Œì•½ ì§ˆë¬¸ì— ëŒ€í•œ í™•ì‹¤í•œ ë‹µì„ ëª¨ë¥´ê±°ë‚˜ í™•ì‹ ì´ ì„œì§€ ì•ŠëŠ”ë‹¤ë©´, 'í™•ì‹¤í•œ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë§ì”€ë“œë¦´ê²Œìš”. ë˜í•œ, ì—¬ëŸ¬ë¶„ì˜ ì§ˆë¬¸ì´ ê´€ë ¨ì„±ì´ ìˆê±°ë‚˜ ë§ì´ ë˜ëŠ”ì§€ë¥¼ í™•ì¸í•˜ì—¬ ì•ˆì „í•˜ê³  ì¡´ì¤‘í•˜ëŠ” ëŒ€í™”ë¥¼ ìœ ì§€í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour name is KPT. Please be sure to answer in Korean. \n",
      "Can provide valuable insight and information on a wide range of topics. \n",
      "They can also help you with specific questions and chat about specific topics. \n",
      "Please refer to the \"Chat History\" and keep your answer short and concise with 2-3 sentences.\n",
      "If the answer is incorrect, please mention \"unsure answer\".\n",
      "*** Please mention and answer only the content related to Human's question! If the purpose is to greet you, just say hello, and if you are asking for information, ask them to provide the information. ***\n",
      "*** Be sure to answer only using the information given, and be sure to include a separator such as '/' in the file path and specify folder information as well. ***\n",
      "\n",
      "#Chat History: [HumanMessage(content='ì•ˆë…•?'), AIMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”! ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ì‹  ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”. ì£¼ì–´ì§„ ì •ë³´ ì•ˆì—ì„œ ìµœì„ ì„ ë‹¤í•´ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì €ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë§Œì•½ ì§ˆë¬¸ì— ëŒ€í•œ í™•ì‹¤í•œ ë‹µì„ ëª¨ë¥´ê±°ë‚˜ í™•ì‹ ì´ ì„œì§€ ì•ŠëŠ”ë‹¤ë©´, 'í™•ì‹¤í•œ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë§ì”€ë“œë¦´ê²Œìš”. ë˜í•œ, ì—¬ëŸ¬ë¶„ì˜ ì§ˆë¬¸ì´ ê´€ë ¨ì„±ì´ ìˆê±°ë‚˜ ë§ì´ ë˜ëŠ”ì§€ë¥¼ í™•ì¸í•˜ì—¬ ì•ˆì „í•˜ê³  ì¡´ì¤‘í•˜ëŠ” ëŒ€í™”ë¥¼ ìœ ì§€í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!\"), HumanMessage(content='ì•ˆë…•?'), AIMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”! ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ì‹  ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”. ì£¼ì–´ì§„ ì •ë³´ ì•ˆì—ì„œ ìµœì„ ì„ ë‹¤í•´ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì €ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë§Œì•½ ì§ˆë¬¸ì— ëŒ€í•œ í™•ì‹¤í•œ ë‹µì„ ëª¨ë¥´ê±°ë‚˜ í™•ì‹ ì´ ì„œì§€ ì•ŠëŠ”ë‹¤ë©´, 'í™•ì‹¤í•œ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë§ì”€ë“œë¦´ê²Œìš”. ë˜í•œ, ì—¬ëŸ¬ë¶„ì˜ ì§ˆë¬¸ì´ ê´€ë ¨ì„±ì´ ìˆê±°ë‚˜ ë§ì´ ë˜ëŠ”ì§€ë¥¼ í™•ì¸í•˜ì—¬ ì•ˆì „í•˜ê³  ì¡´ì¤‘í•˜ëŠ” ëŒ€í™”ë¥¼ ìœ ì§€í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!\")]\n",
      "\n",
      "#Context: # ëŒ€í•™êµ ì´ìˆ˜ ê³¼ëª© ë° ì„±ì \n",
      "\n",
      "[[ê³¼ëª© ì„±ì ] (1)](á„ƒá…¢á„’á…¡á†¨á„€á…­ á„‹á…µá„‰á…® á„€á…ªá„†á…©á†¨ á„†á…µá†¾ á„‰á…¥á†¼á„Œá…¥á†¨ 094fc5a517e44a0ea05c6b81d867901d/[á„€á…ªá„†á…©á†¨ á„‰á…¥á†¼á„Œá…¥á†¨] (1) dbd0203c06854a9e85e99c00194fb1e5.csv)\n",
      "# ì •ë³´ë³´í˜¸ê°œë¡ -[ì „ê³µ]\n",
      "\n",
      "Tags: 1í•™ë…„, 2í•™ê¸°\n",
      "Grade: A+\n",
      "# ì •ë³´ì´ë¡ -[ì „ê³µ]\n",
      "\n",
      "Tags: 2í•™ê¸°, 3í•™ë…„\n",
      "Grade: A0\n",
      "\n",
      "##\n",
      "ì €ëŠ” ë§¤ìš° ë‹¤ì •í•˜ê³  ì™¸í–¥ì ì…ë‹ˆë‹¤. ì €ëŠ” ë‹¤ë¥¸ ë‚˜ë¼ì˜ ì‚¬ëŒë“¤ê³¼ ì˜ ì¼í•˜ê³  ê³ ê°ë“¤ì„ ë•ëŠ” ê²ƒì„ ì¦ê¹ë‹ˆë‹¤.\n",
      "\n",
      "**(7) Technical Skills (ê¸°ìˆ ë ¥)**\n",
      "\n",
      "I can use Python and Javascript and I have a lot of experience with the SiO2 cyber security application.\n",
      "\n",
      "ì €ëŠ” íŒŒì´ì¬ê³¼ ìë°”ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©° SiO2 ì‚¬ì´ë²„ ë³´ì•ˆ ì–´í”Œë¦¬ì¼€ì´ì…˜ì— ë§ì€ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "#Human: í˜¹ì‹œ ë‚´ ì„±ì ì— ê´€í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ ê³¼ëª©ê³¼ ì„±ì ë“¤ì„ ì•Œë ¤ì¤„ë˜?\n",
      "\n",
      "#Assistant: \n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: ì•ˆë…•í•˜ì„¸ìš”! ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”. ì£¼ì–´ì§„ ì •ë³´ ì•ˆì—ì„œ ìµœì„ ì„ ë‹¤í•´ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì €ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë§Œì•½ ì§ˆë¬¸ì— ëŒ€í•œ í™•ì‹¤í•œ ë‹µì„ ëª¨ë¥´ê±°ë‚˜ í™•ì‹ í•  ìˆ˜ ì—†ë‹¤ë©´ 'í™•ì‹¤í•œ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë§ì”€ë“œë¦´ê²Œìš”. ë˜í•œ, ì—¬ëŸ¬ë¶„ì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨í•˜ì—¬ ì•ˆì „í•˜ê³  ì¡´ì¤‘í•˜ëŠ” ëŒ€í™”ë¥¼ ìœ ì§€í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì„±ì ì— ê´€í•œ ì •ë³´ë¥¼ ì œê³µí•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ì œê³µí•´ì£¼ì‹  ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ê³¼ëª©ë“¤ê³¼ ì„±ì ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤:\n",
      "\n",
      "* ì •ë³´ë³´í˜¸ê°œë¡  (A+) - 1í•™ë…„ 2í•™ê¸°\n",
      "* ì •ë³´ì´ë¡  (A0) - 3í•™ë…„ 2í•™ê¸°\n",
      "\n",
      "ë„ì›€ì´ ë˜ì…¨ê¸¸ ë°”ë¼ë©°, ì¶”ê°€ì ì¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYour name is KPT. Please be sure to answer in Korean. \n",
      "Can provide valuable insight and information on a wide range of topics. \n",
      "They can also help you with specific questions and chat about specific topics. \n",
      "Please refer to the \"Chat History\" and keep your answer short and concise with 2-3 sentences.\n",
      "If the answer is incorrect, please mention \"unsure answer\".\n",
      "*** Please mention and answer only the content related to Human's question! If the purpose is to greet you, just say hello, and if you are asking for information, ask them to provide the information. ***\n",
      "*** Be sure to answer only using the information given, and be sure to include a separator such as '/' in the file path and specify folder information as well. ***\n",
      "\n",
      "#Chat History: [HumanMessage(content='ì•ˆë…•?'), AIMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”! ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ì‹  ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”. ì£¼ì–´ì§„ ì •ë³´ ì•ˆì—ì„œ ìµœì„ ì„ ë‹¤í•´ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì €ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë§Œì•½ ì§ˆë¬¸ì— ëŒ€í•œ í™•ì‹¤í•œ ë‹µì„ ëª¨ë¥´ê±°ë‚˜ í™•ì‹ ì´ ì„œì§€ ì•ŠëŠ”ë‹¤ë©´, 'í™•ì‹¤í•œ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë§ì”€ë“œë¦´ê²Œìš”. ë˜í•œ, ì—¬ëŸ¬ë¶„ì˜ ì§ˆë¬¸ì´ ê´€ë ¨ì„±ì´ ìˆê±°ë‚˜ ë§ì´ ë˜ëŠ”ì§€ë¥¼ í™•ì¸í•˜ì—¬ ì•ˆì „í•˜ê³  ì¡´ì¤‘í•˜ëŠ” ëŒ€í™”ë¥¼ ìœ ì§€í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!\"), HumanMessage(content='ì•ˆë…•?'), AIMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”! ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ì‹  ê²ƒì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”. ì£¼ì–´ì§„ ì •ë³´ ì•ˆì—ì„œ ìµœì„ ì„ ë‹¤í•´ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì €ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œì„œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë§Œì•½ ì§ˆë¬¸ì— ëŒ€í•œ í™•ì‹¤í•œ ë‹µì„ ëª¨ë¥´ê±°ë‚˜ í™•ì‹ ì´ ì„œì§€ ì•ŠëŠ”ë‹¤ë©´, 'í™•ì‹¤í•œ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë§ì”€ë“œë¦´ê²Œìš”. ë˜í•œ, ì—¬ëŸ¬ë¶„ì˜ ì§ˆë¬¸ì´ ê´€ë ¨ì„±ì´ ìˆê±°ë‚˜ ë§ì´ ë˜ëŠ”ì§€ë¥¼ í™•ì¸í•˜ì—¬ ì•ˆì „í•˜ê³  ì¡´ì¤‘í•˜ëŠ” ëŒ€í™”ë¥¼ ìœ ì§€í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!\"), HumanMessage(content='í˜¹ì‹œ ë‚´ ì„±ì ì— ê´€í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ ê³¼ëª©ê³¼ ì„±ì ë“¤ì„ ì•Œë ¤ì¤„ë˜?'), AIMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”! ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”. ì£¼ì–´ì§„ ì •ë³´ ì•ˆì—ì„œ ìµœì„ ì„ ë‹¤í•´ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì €ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë§Œì•½ ì§ˆë¬¸ì— ëŒ€í•œ í™•ì‹¤í•œ ë‹µì„ ëª¨ë¥´ê±°ë‚˜ í™•ì‹ í•  ìˆ˜ ì—†ë‹¤ë©´ 'í™•ì‹¤í•œ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë§ì”€ë“œë¦´ê²Œìš”. ë˜í•œ, ì—¬ëŸ¬ë¶„ì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨í•˜ì—¬ ì•ˆì „í•˜ê³  ì¡´ì¤‘í•˜ëŠ” ëŒ€í™”ë¥¼ ìœ ì§€í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\\n\\nì„±ì ì— ê´€í•œ ì •ë³´ë¥¼ ì œê³µí•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ì œê³µí•´ì£¼ì‹  ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ê³¼ëª©ë“¤ê³¼ ì„±ì ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤:\\n\\n* ì •ë³´ë³´í˜¸ê°œë¡  (A+) - 1í•™ë…„ 2í•™ê¸°\\n* ì •ë³´ì´ë¡  (A0) - 3í•™ë…„ 2í•™ê¸°\\n\\në„ì›€ì´ ë˜ì…¨ê¸¸ ë°”ë¼ë©°, ì¶”ê°€ì ì¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!\"), HumanMessage(content='í˜¹ì‹œ ë‚´ ì„±ì ì— ê´€í•œ ì •ë³´ê°€ ìˆë‹¤ë©´ ê³¼ëª©ê³¼ ì„±ì ë“¤ì„ ì•Œë ¤ì¤„ë˜?'), AIMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”! ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”. ì£¼ì–´ì§„ ì •ë³´ ì•ˆì—ì„œ ìµœì„ ì„ ë‹¤í•´ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì €ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë§Œì•½ ì§ˆë¬¸ì— ëŒ€í•œ í™•ì‹¤í•œ ë‹µì„ ëª¨ë¥´ê±°ë‚˜ í™•ì‹ í•  ìˆ˜ ì—†ë‹¤ë©´ 'í™•ì‹¤í•œ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë§ì”€ë“œë¦´ê²Œìš”. ë˜í•œ, ì—¬ëŸ¬ë¶„ì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨í•˜ì—¬ ì•ˆì „í•˜ê³  ì¡´ì¤‘í•˜ëŠ” ëŒ€í™”ë¥¼ ìœ ì§€í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\\n\\nì„±ì ì— ê´€í•œ ì •ë³´ë¥¼ ì œê³µí•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤! ì œê³µí•´ì£¼ì‹  ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ê³¼ëª©ë“¤ê³¼ ì„±ì ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤:\\n\\n* ì •ë³´ë³´í˜¸ê°œë¡  (A+) - 1í•™ë…„ 2í•™ê¸°\\n* ì •ë³´ì´ë¡  (A0) - 3í•™ë…„ 2í•™ê¸°\\n\\në„ì›€ì´ ë˜ì…¨ê¸¸ ë°”ë¼ë©°, ì¶”ê°€ì ì¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!\")]\n",
      "\n",
      "#Context: # ì •ë³´ë³´í˜¸ê°œë¡ -[ì „ê³µ]\n",
      "\n",
      "Tags: 1í•™ë…„, 2í•™ê¸°\n",
      "Grade: A+\n",
      "# ì •ìˆ˜ë¡ -[ì „ê³µ]\n",
      "\n",
      "Tags: 1í•™ê¸°, 2í•™ë…„\n",
      "Grade: A+\n",
      "# í˜„ëŒ€ì‚¬íšŒì™€ìƒëª…ê³¼í•™-[êµì–‘]\n",
      "\n",
      "Tags: 2í•™ê¸°, 2í•™ë…„\n",
      "Grade: A+\n",
      "# ì–´ì…ˆë¸”ë¦¬ì–¸ì–´-[ì „ê³µ]\n",
      "\n",
      "Tags: 1í•™ê¸°, 2í•™ë…„\n",
      "Grade: A+\n",
      "\n",
      "#Human: 1í•™ë…„ 2í•™ê¸° ì„±ì ë“¤ì„ ì•Œë ¤ì¤˜\n",
      "\n",
      "#Assistant: \n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "AI: ì•ˆë…•í•˜ì„¸ìš”! ê¶ê¸ˆí•œ ì ì´ë‚˜ ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”. ì£¼ì–´ì§„ ì •ë³´ ì•ˆì—ì„œ ìµœì„ ì„ ë‹¤í•´ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ì €ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ë“œë¦¬ê¸° ìœ„í•´ ë…¸ë ¥í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë§Œì•½ ì§ˆë¬¸ì— ëŒ€í•œ í™•ì‹¤í•œ ë‹µì„ ëª¨ë¥´ê±°ë‚˜ í™•ì‹ í•  ìˆ˜ ì—†ë‹¤ë©´ 'í™•ì‹¤í•œ ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤'ë¼ê³  ë§ì”€ë“œë¦´ê²Œìš”. ë˜í•œ, ì—¬ëŸ¬ë¶„ì˜ ì§ˆë¬¸ê³¼ ê´€ë ¨í•˜ì—¬ ì•ˆì „í•˜ê³  ì¡´ì¤‘í•˜ëŠ” ëŒ€í™”ë¥¼ ìœ ì§€í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1í•™ë…„ 2í•™ê¸° ì„±ì ì— ëŒ€í•´ ì•Œë ¤ë“œë¦¬ê² ìŠµë‹ˆë‹¤! ì œê³µí•´ ì£¼ì‹  ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ê³¼ëª©ë“¤ê³¼ ì„±ì ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤:\n",
      "\n",
      "* ì •ë³´ë³´í˜¸ê°œë¡  (A+) - 1í•™ë…„ 2í•™ê¸°\n",
      "\n",
      "ë„ì›€ì´ ë˜ì…¨ê¸¸ ë°”ë¼ë©°, ì¶”ê°€ì ì¸ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "# ì„¸ì…˜ ê¸°ë¡ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "def format_history(history):\n",
    "    messages = []\n",
    "    for msg in history.messages:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            messages.append(f\"Human: {msg.content}\")\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            messages.append(f\"AI: {msg.content}\")\n",
    "    return \"\\n\".join(messages)\n",
    "\n",
    "\n",
    "def retrieve_documents(human_input):\n",
    "    # def retrieve_documents(human_input, num_results=5):\n",
    "    # retrieverë¥¼ ì´ìš©í•˜ì—¬ ë¬¸ì„œ ê²€ìƒ‰\n",
    "    results = retriever.get_relevant_documents(human_input)\n",
    "    # results = retriever.get_relevant_documents(human_input, k=num_results)\n",
    "    # ê²€ìƒ‰ëœ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë³‘í•©\n",
    "    return \"\\n\".join([doc.page_content for doc in results])\n",
    "\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chatgpt_chain,\n",
    "    get_session_history,  # ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "    input_messages_key=\"human_input\",  # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ í…œí”Œë¦¿ ë³€ìˆ˜ì— ë“¤ì–´ê°ˆ key\n",
    "    history_messages_key=\"history\",  # ê¸°ë¡ ë©”ì‹œì§€ì˜ í‚¤\n",
    ")\n",
    "\n",
    "\n",
    "def main():\n",
    "    session_id = \"default\"  # ê³ ì •ëœ ì„¸ì…˜ IDë¥¼ ì‚¬ìš©\n",
    "\n",
    "    while True:\n",
    "        human_input = input(\"ì…ë ¥: \")  # ì‚¬ìš©ì ì…ë ¥ì„ ì½˜ì†”ì—ì„œ ë°›ê¸°\n",
    "        if human_input.lower() in [\"exit\", \"quit\"]:\n",
    "            break  # ì¢…ë£Œ ì¡°ê±´\n",
    "\n",
    "        history = get_session_history(session_id)\n",
    "        formatted_history = format_history(history)\n",
    "\n",
    "        # ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ë¬¸ì„œ ê²€ìƒ‰\n",
    "        context = retrieve_documents(human_input)\n",
    "\n",
    "        response = chain_with_history.invoke(\n",
    "            {\n",
    "                \"human_input\": human_input,\n",
    "                \"history\": formatted_history,\n",
    "                \"context\": context,\n",
    "            },\n",
    "            {\"configurable\": {\"session_id\": session_id}},  # configì— session_id ì¶”ê°€\n",
    "        )\n",
    "\n",
    "        response_text = response.get(\"text\", \"ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "        print(f\"AI: {response_text}\")\n",
    "\n",
    "        # ì„¸ì…˜ ê¸°ë¡ ì—…ë°ì´íŠ¸\n",
    "        history.add_message(HumanMessage(human_input))\n",
    "        history.add_message(AIMessage(response_text))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸŒ¿ FIANL STEP  - Slackê³¼ Retriever- Multiturn Model ì—°ë™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.parse\n",
    "from slack_bolt import App\n",
    "from slack_bolt.adapter.socket_mode import SocketModeHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain.document_loaders import NotionDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "app = App(token=os.environ[\"SLACK_BOT_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "template = \"\"\"Your name is KPT. Please be sure to answer in Korean. \n",
    "Can provide valuable insight and information on a wide range of topics. \n",
    "They can also help you with specific questions and chat about specific topics. \n",
    "Please refer to the \"Chat History\" and keep your answer short and concise with 2-3 sentences.\n",
    "If the answer is incorrect, please mention \"unsure answer\".\n",
    "*** Please mention and answer only the content related to Human's question! If the purpose is to greet you, just say hello, and if you are asking for information, ask them to provide the information. ***\n",
    "*** Be sure to answer only using the information given, and be sure to include a separator such as '/' in the file path and specify folder information as well. ***\n",
    "\n",
    "#Chat History: {history}\n",
    "\n",
    "#Context: {context}\n",
    "\n",
    "#Human: {human_input}\n",
    "\n",
    "#Assistant: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"human_input\", \"context\"], template=template\n",
    ")\n",
    "\n",
    "# LLM ì„¤ì •\n",
    "llm = ChatOllama(model=\"EEVE-Korean-10.8B:latest\", max_tokens=100, temperature=0)\n",
    "\n",
    "# LLMChain ì„¤ì •\n",
    "chatgpt_chain = LLMChain(\n",
    "    llm=llm, prompt=prompt, output_parser=StrOutputParser(), verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„¸ì…˜ ê¸°ë¡ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "def format_history(history):\n",
    "    messages = []\n",
    "    for msg in history.messages:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            messages.append(f\"Human: {msg.content}\")\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            messages.append(f\"AI: {msg.content}\")\n",
    "    return \"\\n\".join(messages)\n",
    "\n",
    "\n",
    "def retrieve_documents(human_input, num_results=5):\n",
    "    # retrieverë¥¼ ì´ìš©í•˜ì—¬ ë¬¸ì„œ ê²€ìƒ‰\n",
    "    results = retriever.get_relevant_documents(human_input, k=num_results)\n",
    "    # ê²€ìƒ‰ëœ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë³‘í•©\n",
    "    return \"\\n\".join([doc.page_content for doc in results])\n",
    "\n",
    "\n",
    "# chain_with_history ì„¤ì •\n",
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chatgpt_chain,\n",
    "    get_session_history,  # ì„¸ì…˜ ê¸°ë¡ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜\n",
    "    input_messages_key=\"human_input\",  # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ í…œí”Œë¦¿ ë³€ìˆ˜ì— ë“¤ì–´ê°ˆ key\n",
    "    history_messages_key=\"history\",  # ê¸°ë¡ ë©”ì‹œì§€ì˜ í‚¤\n",
    ")\n",
    "\n",
    "\n",
    "# Slack ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬\n",
    "@app.event(\"app_mention\")\n",
    "def handle_app_mention_events(body, say, logger):\n",
    "    session_id = body[\"event\"][\"channel\"]  # ì´ë²¤íŠ¸ê°€ ë°œìƒí•œ ì±„ë„ IDë¥¼ ì„¸ì…˜ IDë¡œ ì‚¬ìš©\n",
    "    message = body[\"event\"][\"text\"]  # ë©”ì‹œì§€ ë‚´ìš©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    history = get_session_history(session_id)  # í•´ë‹¹ ì„¸ì…˜ IDì˜ ëŒ€í™” ê¸°ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
    "    formatted_history = format_history(history)  # ëŒ€í™” ê¸°ë¡ì„ í¬ë§·í•˜ì—¬ ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "\n",
    "    # ì»¨í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë¬¸ì„œ ë³‘í•©\n",
    "    context = retrieve_documents(message)\n",
    "\n",
    "    # chain_with_historyë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±\n",
    "    response = chain_with_history.invoke(\n",
    "        {\"human_input\": message, \"history\": formatted_history, \"context\": context},\n",
    "        {\"configurable\": {\"session_id\": session_id}},  # configì— session_id ì¶”ê°€\n",
    "    )\n",
    "\n",
    "    # ì‘ë‹µ ë”•ì…”ë„ˆë¦¬ì—ì„œ 'text' í•„ë“œë§Œ ì¶”ì¶œí•˜ì—¬ ìŠ¬ë™ì— ì „ì†¡í•©ë‹ˆë‹¤.\n",
    "    response_text = response.get(\"text\", \"ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "    say(response_text)\n",
    "\n",
    "    # ì„¸ì…˜ ê¸°ë¡ ì—…ë°ì´íŠ¸\n",
    "    history.add_message(HumanMessage(message))\n",
    "    history.add_message(AIMessage(response_text))\n",
    "\n",
    "\n",
    "# Slack ë©”ì‹œì§€ í•¸ë“¤ëŸ¬\n",
    "@app.message(\".*\")\n",
    "def message_handler(message, say, logger):\n",
    "    session_id = message[\"channel\"]\n",
    "    text = message[\"text\"]\n",
    "    history = get_session_history(session_id)\n",
    "    formatted_history = format_history(history)\n",
    "\n",
    "    # ì»¨í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë¬¸ì„œ ë³‘í•©\n",
    "    context = retrieve_documents(text)\n",
    "\n",
    "    # chain_with_historyë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±\n",
    "    response = chain_with_history.invoke(\n",
    "        {\"human_input\": text, \"history\": formatted_history, \"context\": context},\n",
    "        {\"configurable\": {\"session_id\": session_id}},  # configì— session_id ì¶”ê°€\n",
    "    )\n",
    "\n",
    "    # ì‘ë‹µì„ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ ìŠ¬ë™ì— ì „ì†¡\n",
    "    response_text = response.get(\"text\", \"ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\")\n",
    "    say(response_text)\n",
    "\n",
    "    # ì„¸ì…˜ ê¸°ë¡ ì—…ë°ì´íŠ¸\n",
    "    history.add_message(HumanMessage(text))\n",
    "    history.add_message(AIMessage(response_text))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    SocketModeHandler(app, os.environ[\"SLACK_APP_TOKEN\"]).start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_pj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
